{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYzn2Dce+HPBDYJfNc0D13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jockyuiz/3D-Machine-Learning/blob/master/GRU_Stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f-KW5S_glkfD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# 1. Improved GRU Module\n",
        "#############################\n",
        "\n",
        "class ImprovedGRUCell(nn.Module):\n",
        "    \"\"\"\n",
        "    改进版 GRU 单步 Cell（Gated Recurrent Unit）\n",
        "    其中：\n",
        "      - Update Gate (更新门): 控制新旧信息的融合\n",
        "      - 使用 Attention (注意力机制) 替换传统的 Reset Gate (重置门)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, attn_size):\n",
        "        super(ImprovedGRUCell, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # 更新门参数\n",
        "        self.W_z = nn.Linear(input_size, hidden_size)\n",
        "        self.U_z = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # 候选隐藏状态参数\n",
        "        self.W_h = nn.Linear(input_size, hidden_size)\n",
        "        self.U_h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "        # 注意力机制参数（用于替代 reset gate）\n",
        "        # 将上一时刻隐藏状态作为 Query，当前输入作为 Key 和 Value\n",
        "        self.W_q = nn.Linear(hidden_size, attn_size)\n",
        "        self.W_k = nn.Linear(input_size, attn_size)\n",
        "        self.W_v = nn.Linear(input_size, hidden_size)\n",
        "        self.attn_scale = torch.sqrt(torch.tensor(attn_size, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        x: 当前输入，形状 (batch, input_size)\n",
        "        h_prev: 上一时刻隐藏状态，形状 (batch, hidden_size)\n",
        "        \"\"\"\n",
        "        # 更新门计算：z = sigmoid(W_z * x + U_z * h_prev)\n",
        "        z = torch.sigmoid(self.W_z(x) + self.U_z(h_prev))\n",
        "\n",
        "        # 注意力机制替代重置门\n",
        "        q = self.W_q(h_prev)      # Query, 形状 (batch, attn_size)\n",
        "        k = self.W_k(x)           # Key,     形状 (batch, attn_size)\n",
        "        v = self.W_v(x)           # Value,   形状 (batch, hidden_size)\n",
        "        # 计算缩放点积注意力分数 (Scaled Dot-Product Attention)\n",
        "        attn_score = torch.sum(q * k, dim=-1, keepdim=True) / self.attn_scale  # (batch, 1)\n",
        "        # 使用 sigmoid 得到注意力权重（简化版，不跨时间步聚合）\n",
        "        alpha = torch.sigmoid(attn_score)  # (batch, 1)\n",
        "        r_prime = alpha * v  # 得到新的“重置门”输出，形状 (batch, hidden_size)\n",
        "\n",
        "        # 计算候选隐藏状态：h_tilde = tanh(W_h * x + r_prime ⊙ (U_h * h_prev) + b_h)\n",
        "        h_tilde = torch.tanh(self.W_h(x) + r_prime * self.U_h(h_prev) + self.b_h)\n",
        "\n",
        "        # 最终隐藏状态更新：h = (1 - z) ⊙ h_prev + z ⊙ h_tilde\n",
        "        h = (1 - z) * h_prev + z * h_tilde\n",
        "        return h"
      ],
      "metadata": {
        "id": "Vx_Ih3bAlrFe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedGRU(nn.Module):\n",
        "    \"\"\"\n",
        "    改进版 GRU 模块，处理输入的整个时间序列\n",
        "    输入 x 的形状：(batch, seq_len, input_size)\n",
        "    输出所有时间步的隐藏状态，形状：(batch, seq_len, hidden_size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, attn_size):\n",
        "        super(ImprovedGRU, self).__init__()\n",
        "        self.cell = ImprovedGRUCell(input_size, hidden_size, attn_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        # 初始化隐藏状态，全零\n",
        "        h = torch.zeros(batch_size, self.cell.hidden_size, device=x.device)\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            h = self.cell(x[:, t, :], h)\n",
        "            outputs.append(h.unsqueeze(1))\n",
        "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, hidden_size)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "K__DPi5tl9Bf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# 2. Graph Attention Network (GAT) Module\n",
        "#############################\n",
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Attention Layer\n",
        "    通过自注意力 (Self-Attention) 机制动态计算节点之间的权重，\n",
        "    并聚合邻居节点特征。参考公式：\n",
        "      e_ij = LeakyReLU(a^T [Wh_i || Wh_j])\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, dropout=0.1, alpha=0.2, concat=True):\n",
        "        super(GraphAttentionLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.W = nn.Linear(in_features, out_features, bias=False)\n",
        "        self.a = nn.Linear(2*out_features, 1, bias=False)\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, h, adj):\n",
        "        \"\"\"\n",
        "        h: 输入节点特征，形状 (N, in_features)，N为节点数（股票数）\n",
        "        adj: 邻接矩阵，形状 (N, N)，非零表示存在边连接\n",
        "        \"\"\"\n",
        "        Wh = self.W(h)  # (N, out_features)\n",
        "        N = Wh.size()[0]\n",
        "        # 构造所有节点对的拼接表示：[Wh_i || Wh_j]\n",
        "        a_input = torch.cat([Wh.repeat(1, N).view(N*N, -1), Wh.repeat(N, 1)], dim=1)\n",
        "        a_input = a_input.view(N, N, 2*self.out_features)\n",
        "        # 计算注意力分数 e_ij\n",
        "        e = self.leakyrelu(self.a(a_input).squeeze(2))  # (N, N)\n",
        "\n",
        "        # 对非邻居设置为一个极小值\n",
        "        zero_vec = -9e15 * torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "        attention = F.softmax(attention, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "        # 聚合邻居特征\n",
        "        h_prime = torch.matmul(attention, Wh)  # (N, out_features)\n",
        "        if self.concat:\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            return h_prime\n"
      ],
      "metadata": {
        "id": "P1h-fwlWmHxv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# 3. Multi-head Cross-Attention Module\n",
        "#############################\n",
        "\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head Cross-Attention 模块\n",
        "    将 query (查询) 与 key, value (键、值) 进行交互，捕获不同子空间的信息。\n",
        "    参考 Transformer 中的 Multi-head Attention 机制。\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadCrossAttention, self).__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model 必须能被 num_heads 整除\"\n",
        "        self.num_heads = num_heads\n",
        "        self.d_head = d_model // num_heads\n",
        "\n",
        "        self.W_Q = nn.Linear(d_model, d_model)\n",
        "        self.W_K = nn.Linear(d_model, d_model)\n",
        "        self.W_V = nn.Linear(d_model, d_model)\n",
        "        self.out_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, query, key, value):\n",
        "        \"\"\"\n",
        "        query: (batch, seq_len_q, d_model)\n",
        "        key, value: (batch, seq_len_k, d_model)\n",
        "        输出: (batch, seq_len_q, d_model)\n",
        "        \"\"\"\n",
        "        batch_size = query.size(0)\n",
        "        Q = self.W_Q(query)  # (batch, seq_len_q, d_model)\n",
        "        K = self.W_K(key)    # (batch, seq_len_k, d_model)\n",
        "        V = self.W_V(value)  # (batch, seq_len_k, d_model)\n",
        "\n",
        "        # 分头处理\n",
        "        Q = Q.view(batch_size, -1, self.num_heads, self.d_head).transpose(1,2)  # (batch, num_heads, seq_len_q, d_head)\n",
        "        K = K.view(batch_size, -1, self.num_heads, self.d_head).transpose(1,2)  # (batch, num_heads, seq_len_k, d_head)\n",
        "        V = V.view(batch_size, -1, self.num_heads, self.d_head).transpose(1,2)  # (batch, num_heads, seq_len_k, d_head)\n",
        "\n",
        "        # 计算缩放点积注意力\n",
        "        scores = torch.matmul(Q, K.transpose(-2,-1)) / (self.d_head ** 0.5)  # (batch, num_heads, seq_len_q, seq_len_k)\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attn, V)  # (batch, num_heads, seq_len_q, d_head)\n",
        "\n",
        "        # 将多头拼接\n",
        "        context = context.transpose(1,2).contiguous().view(batch_size, -1, self.num_heads * self.d_head)\n",
        "        output = self.out_linear(context)  # (batch, seq_len_q, d_model)\n",
        "        return output"
      ],
      "metadata": {
        "id": "dquJ2MSHmKaq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################\n",
        "# 4. 整体 MCI-GRU 模型\n",
        "#############################\n",
        "\n",
        "class MCI_GRU(nn.Module):\n",
        "    \"\"\"\n",
        "    整体 MCI-GRU 模型，由以下四部分组成：\n",
        "      I. Improved GRU 捕获时序特征 -> 输出 A1 (shape: (batch, hidden_size))\n",
        "      II. GAT 捕获横截面特征 -> 输出 A2 (shape: (batch, gat_hidden))\n",
        "      III. 多头交叉注意力捕获市场隐状态 -> 分别对 A1 与 A2 进行交互，输出 B1 和 B2 (shape: (batch, d_model))\n",
        "      IV. 将 A1, A2, B1, B2 拼接后经过额外 GAT 层与全连接层得到最终预测\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, attn_size,\n",
        "                 gat_in, gat_hidden, d_model, num_heads, num_latent_states, final_out_dim):\n",
        "        super(MCI_GRU, self).__init__()\n",
        "        # 模块 I：Improved GRU\n",
        "        self.improved_gru = ImprovedGRU(input_size, hidden_size, attn_size)\n",
        "        # 模块 II：GAT\n",
        "        self.gat = GraphAttentionLayer(gat_in, gat_hidden, dropout=0.1, alpha=0.2, concat=True)\n",
        "        # 初始化市场隐状态向量（Learnable latent states）\n",
        "        # R1 用于时序信息，R2 用于横截面信息；尺寸均为 (num_latent_states, d_model)\n",
        "        self.R1 = nn.Parameter(torch.randn(num_latent_states, d_model))\n",
        "        self.R2 = nn.Parameter(torch.randn(num_latent_states, d_model))\n",
        "        # 模块 III：多头交叉注意力\n",
        "        self.cross_attn1 = MultiHeadCrossAttention(d_model, num_heads)\n",
        "        self.cross_attn2 = MultiHeadCrossAttention(d_model, num_heads)\n",
        "        # 模块 IV：预测层——额外的 GAT 层和全连接层\n",
        "        self.pred_gat1 = GraphAttentionLayer(final_out_dim, final_out_dim, dropout=0.1, alpha=0.2, concat=True)\n",
        "        self.pred_gat2 = GraphAttentionLayer(final_out_dim, final_out_dim, dropout=0.1, alpha=0.2, concat=False)\n",
        "        self.fc = nn.Linear(final_out_dim, 1)  # 最终预测输出一个标量（例如，未来收益率）\n",
        "\n",
        "    def forward(self, x_time, x_graph, adj):\n",
        "        \"\"\"\n",
        "        x_time: 时序数据，形状 (batch, seq_len, input_size)，每个样本对应一只股票的历史数据\n",
        "        x_graph: 横截面数据，形状 (N, gat_in)，N 与 batch 大小相同，代表当前时刻每只股票的特征\n",
        "        adj: 邻接矩阵，形状 (N, N)，描述股票之间的关系（例如，根据历史相关性构造）\n",
        "        \"\"\"\n",
        "        # 模块 I：Improved GRU 提取时序特征，取最后一个时间步作为 A1，形状 (batch, hidden_size)\n",
        "        gru_out = self.improved_gru(x_time)\n",
        "        A1 = gru_out[:, -1, :]\n",
        "\n",
        "        # 模块 II：GAT 提取横截面特征，输出 A2，形状 (N, gat_hidden)\n",
        "        A2 = self.gat(x_graph, adj)\n",
        "\n",
        "        # 模块 III：多头交叉注意力\n",
        "        # 先对 A1 与 A2 添加时间步维度（视为序列长度为1）\n",
        "        A1_unsq = A1.unsqueeze(1)  # (batch, 1, hidden_size)\n",
        "        A2_unsq = A2.unsqueeze(1)  # (batch, 1, gat_hidden)\n",
        "        # 为简化，要求 hidden_size, gat_hidden 均等于 d_model，此处假定已预设好\n",
        "        # 与隐状态 R1 和 R2 进行交互\n",
        "        R1_batch = self.R1.unsqueeze(0).expand(A1.size(0), -1, -1)  # (batch, num_latent_states, d_model)\n",
        "        B1 = self.cross_attn1(A1_unsq, R1_batch, R1_batch)  # (batch, 1, d_model)\n",
        "        B1 = B1.squeeze(1)  # (batch, d_model)\n",
        "\n",
        "        R2_batch = self.R2.unsqueeze(0).expand(A2.size(0), -1, -1)  # (batch, num_latent_states, d_model)\n",
        "        B2 = self.cross_attn2(A2_unsq, R2_batch, R2_batch)  # (batch, 1, d_model)\n",
        "        B2 = B2.squeeze(1)  # (batch, d_model)\n",
        "\n",
        "        # 拼接所有特征：A1, A2, B1, B2\n",
        "        Z = torch.cat([A1, A2, B1, B2], dim=1)  # (batch, hidden_size + gat_hidden + 2*d_model)\n",
        "        # 设 final_out_dim = hidden_size + gat_hidden + 2*d_model\n",
        "\n",
        "        # 模块 IV：通过额外 GAT 层进一步整合特征并降维\n",
        "        Z1 = self.pred_gat1(Z, adj)  # (batch, final_out_dim)\n",
        "        Z2 = self.pred_gat2(Z1, adj)  # (batch, final_out_dim)\n",
        "        out = self.fc(Z2)           # (batch, 1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "LwFQoJ2FmPTF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # 设置随机种子，方便复现\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    # 参数设置（可根据需要调整）\n",
        "    batch_size = 10       # 假设有10只股票\n",
        "    seq_len = 10          # 历史时间步长度\n",
        "    input_size = 6        # 每天6个财务指标\n",
        "    hidden_size = 32      # Improved GRU 的隐藏层维度\n",
        "    attn_size = 16        # 注意力机制内部维度\n",
        "    gat_in = 6            # GAT 输入特征维度（与 input_size 一致）\n",
        "    gat_hidden = 32       # GAT 输出维度\n",
        "    d_model = 32          # 多头交叉注意力中使用的模型维度，假设与 hidden_size, gat_hidden 相同\n",
        "    num_heads = 4         # 多头注意力的头数\n",
        "    num_latent_states = 4 # 隐状态数量\n",
        "    # 最终拼接后特征维度：hidden_size + gat_hidden + 2*d_model\n",
        "    final_out_dim = hidden_size + gat_hidden + 2*d_model  # 32 + 32 + 64 = 128\n",
        "\n",
        "    # 构造随机输入数据\n",
        "    # 时序数据：形状 (batch, seq_len, input_size)\n",
        "    x_time = torch.randn(batch_size, seq_len, input_size)\n",
        "    # 横截面数据：形状 (batch, gat_in)；假设与 batch 大小相同\n",
        "    x_graph = torch.randn(batch_size, gat_in)\n",
        "    # 邻接矩阵：形状 (batch, batch)，简单构造一个全1的邻接矩阵（实际中应基于相关性过滤）\n",
        "    adj = torch.ones(batch_size, batch_size)\n",
        "\n",
        "    # 测试 Improved GRU 模块\n",
        "    print(\"==== 测试 Improved GRU ====\")\n",
        "    gru = ImprovedGRU(input_size, hidden_size, attn_size)\n",
        "    gru_out = gru(x_time)  # 输出形状: (batch, seq_len, hidden_size)\n",
        "    print(\"ImprovedGRU 输出形状：\", gru_out.shape)\n",
        "\n",
        "    # 测试 GAT 模块\n",
        "    print(\"\\n==== 测试 GAT 模块 ====\")\n",
        "    gat_layer = GraphAttentionLayer(gat_in, gat_hidden, dropout=0.1, alpha=0.2, concat=True)\n",
        "    gat_out = gat_layer(x_graph, adj)  # 输出形状: (batch, gat_hidden)\n",
        "    print(\"GAT 输出形状：\", gat_out.shape)\n",
        "\n",
        "    # 测试 Multi-head Cross-Attention 模块\n",
        "    print(\"\\n==== 测试 Multi-head Cross-Attention 模块 ====\")\n",
        "    cross_attn = MultiHeadCrossAttention(d_model, num_heads)\n",
        "    # 构造简单的 query 和 key/value 序列，均设形状 (batch, 1, d_model)\n",
        "    query = torch.randn(batch_size, 1, d_model)\n",
        "    key = torch.randn(batch_size, 1, d_model)\n",
        "    value = torch.randn(batch_size, 1, d_model)\n",
        "    attn_out = cross_attn(query, key, value)\n",
        "    print(\"Multi-head Cross-Attention 输出形状：\", attn_out.shape)\n",
        "\n",
        "    # 测试整体 MCI_GRU 模型\n",
        "    print(\"\\n==== 测试整体 MCI_GRU 模型 ====\")\n",
        "    model = MCI_GRU(input_size, hidden_size, attn_size,\n",
        "                    gat_in, gat_hidden, d_model, num_heads, num_latent_states, final_out_dim)\n",
        "    pred = model(x_time, x_graph, adj)  # 输出形状: (batch, 1)\n",
        "    print(\"整体模型预测输出形状：\", pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxQzgSoQmThN",
        "outputId": "ab33b5c6-b80f-48ff-be19-e24fa4509a13"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== 测试 Improved GRU ====\n",
            "ImprovedGRU 输出形状： torch.Size([10, 10, 32])\n",
            "\n",
            "==== 测试 GAT 模块 ====\n",
            "GAT 输出形状： torch.Size([10, 32])\n",
            "\n",
            "==== 测试 Multi-head Cross-Attention 模块 ====\n",
            "Multi-head Cross-Attention 输出形状： torch.Size([10, 1, 32])\n",
            "\n",
            "==== 测试整体 MCI_GRU 模型 ====\n",
            "整体模型预测输出形状： torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance --quiet\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import datetime"
      ],
      "metadata": {
        "id": "3__wJbE_og8h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sp500_tickers():\n",
        "    \"\"\"\n",
        "    从 Wikipedia 获取 S&P 500 成分股列表，并调整部分 ticker 格式（例如 BRK.B -> BRK-B）\n",
        "    \"\"\"\n",
        "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
        "    tables = pd.read_html(url)\n",
        "    df = tables[0]\n",
        "    tickers = df['Symbol'].tolist()\n",
        "    tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
        "    return tickers"
      ],
      "metadata": {
        "id": "6SI-mAoKoknt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 2. 获取单个股票数据\n",
        "#######################################\n",
        "\n",
        "def fetch_stock_data(ticker, start_date, end_date):\n",
        "    \"\"\"\n",
        "    利用 yfinance 获取单个股票的历史数据\n",
        "    参数：\n",
        "      ticker: 股票代码（例如 'AAPL'）\n",
        "      start_date, end_date: 数据时间范围，格式 'YYYY-MM-DD'\n",
        "    返回：\n",
        "      数据 DataFrame，包含 Open, High, Low, Close, Volume 等字段\n",
        "    \"\"\"\n",
        "    stock = yf.Ticker(ticker)\n",
        "    df = stock.history(start=start_date, end=end_date)\n",
        "    # 注意：Yahoo Finance 默认不提供 turnover 数据，这里仅返回已有字段\n",
        "    return df"
      ],
      "metadata": {
        "id": "dEvspn7AorIR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_trading_days(start_date, end_date):\n",
        "    \"\"\"\n",
        "    利用 pandas 计算在 start_date 到 end_date 内的预期交易日数量（仅考虑工作日，freq='B'）\n",
        "    \"\"\"\n",
        "    rng = pd.date_range(start=start_date, end=end_date, freq='B')\n",
        "    return len(rng)"
      ],
      "metadata": {
        "id": "493zF8c6qhJ3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "pQ0Bvg7ywHY5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 2. 数据完整性检查函数\n",
        "#######################################\n",
        "\n",
        "def has_full_data(ticker, train_start, train_end, val_start, val_end, test_start, test_end, tolerance=0.8):\n",
        "    \"\"\"\n",
        "    检查单个股票 ticker 在训练、验证和测试三个时间段内是否具备足够数据覆盖。\n",
        "    方法：计算各时段预期的交易日数（工作日数），要求实际数据行数不少于预期的 tolerance 倍。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        expected_train = count_trading_days(train_start, train_end)\n",
        "        expected_val = count_trading_days(val_start, val_end)\n",
        "        expected_test = count_trading_days(test_start, test_end)\n",
        "\n",
        "        df_train = fetch_stock_data(ticker, train_start, train_end)\n",
        "        df_val = fetch_stock_data(ticker, val_start, val_end)\n",
        "        df_test = fetch_stock_data(ticker, test_start, test_end)\n",
        "    except Exception as e:\n",
        "        print(f\"获取 {ticker} 数据时出错: {e}\")\n",
        "        return False\n",
        "\n",
        "    # 若任一时段数据为空，则直接返回 False（利用 Yahoo API 返回结果）\n",
        "    if df_train.empty or df_val.empty or df_test.empty:\n",
        "        return False\n",
        "\n",
        "    if df_train.shape[0] < tolerance * expected_train:\n",
        "        return False\n",
        "    if df_val.shape[0] < tolerance * expected_val:\n",
        "        return False\n",
        "    if df_test.shape[0] < tolerance * expected_test:\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def get_common_tickers(tickers, train_start, train_end, val_start, val_end, test_start, test_end, tolerance=0.8):\n",
        "    \"\"\"\n",
        "    对给定的 tickers 列表，返回在训练、验证和测试三个时间段内数据完整（满足 tolerance 要求）的股票列表\n",
        "    \"\"\"\n",
        "    common = []\n",
        "    for ticker in tickers:\n",
        "        if has_full_data(ticker, train_start, train_end, val_start, val_end, test_start, test_end, tolerance):\n",
        "            common.append(ticker)\n",
        "        else:\n",
        "            print(f\"股票 {ticker} 数据不完整，已剔除。\")\n",
        "    return common"
      ],
      "metadata": {
        "id": "YhTdmx7IwKiW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 3. 保存有效股票列表及数据的函数\n",
        "#######################################\n",
        "\n",
        "def save_valid_tickers_and_data(output_dir, train_start, train_end, val_start, val_end, test_start, test_end, tolerance=0.8):\n",
        "    \"\"\"\n",
        "    1. 根据指定时间区间筛选出数据完整的股票列表（即在训练、验证、测试集均具备足够数据的股票）。\n",
        "    2. 将有效股票列表保存到 output_dir（例如保存为 valid_tickers.csv）。\n",
        "    3. 对于每个有效股票，从 2018-01-01 至 2023-12-31 的全数据进行查询，并保存为 CSV 文件，方便以后调用。\n",
        "\n",
        "    参数：\n",
        "      output_dir: 输出目录，若不存在则自动创建\n",
        "      train_start, train_end, val_start, val_end, test_start, test_end: 时间区间，格式 'YYYY-MM-DD'\n",
        "      tolerance: 容忍度，例如 0.8 表示实际交易日数不少于预期的 80%\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    all_tickers = get_sp500_tickers()\n",
        "    print(f\"候选股票总数：{len(all_tickers)}\")\n",
        "\n",
        "    # 筛选出在训练、验证和测试集都有足够数据的股票\n",
        "    valid_tickers = get_common_tickers(all_tickers, train_start, train_end, val_start, val_end, test_start, test_end, tolerance)\n",
        "    print(f\"数据完整的股票数量：{len(valid_tickers)}\")\n",
        "\n",
        "    # 保存有效股票列表到 CSV 文件\n",
        "    valid_tickers_df = pd.DataFrame(valid_tickers, columns=[\"Ticker\"])\n",
        "    tickers_file = os.path.join(output_dir, \"valid_tickers.csv\")\n",
        "    valid_tickers_df.to_csv(tickers_file, index=False)\n",
        "    print(f\"有效股票列表已保存到: {tickers_file}\")\n",
        "\n",
        "    # 对于每个有效股票，获取从 2018-01-01 至 2023-12-31 的全数据，并保存为 CSV 文件\n",
        "    full_start, full_end = '2019-01-01', '2024-12-31'\n",
        "    for ticker in valid_tickers:\n",
        "        print(f\"保存 {ticker} 的全数据...\")\n",
        "        df = fetch_stock_data(ticker, full_start, full_end)\n",
        "        if df.empty:\n",
        "            print(f\"股票 {ticker} 在全数据时间区间内数据为空，跳过保存。\")\n",
        "            continue\n",
        "        file_path = os.path.join(output_dir, f\"{ticker}.csv\")\n",
        "        df.to_csv(file_path)\n",
        "    print(\"所有有效股票数据保存完成。\")\n",
        "    return valid_tickers"
      ],
      "metadata": {
        "id": "d0EDFNGrwM_X"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# 4. 调试函数：检查有效股票列表及保存情况\n",
        "#######################################\n",
        "\n",
        "def debug_save_valid_data():\n",
        "    \"\"\"\n",
        "    调试函数，调用 save_valid_tickers_and_data 检查有效股票列表并保存数据\n",
        "    \"\"\"\n",
        "    # 定义论文中规定的时间区间\n",
        "    train_start, train_end = '2019-01-01', '2022-12-31'\n",
        "    val_start, val_end = '2023-01-01', '2023-12-31'\n",
        "    test_start, test_end = '2024-01-01', '2024-12-31'\n",
        "\n",
        "    # 输出目录（可自定义，例如 \"./data/sp500\"）\n",
        "    output_dir = \"./data/sp500\"\n",
        "\n",
        "    valid_tickers = save_valid_tickers_and_data(output_dir, train_start, train_end, val_start, val_end, test_start, test_end, tolerance=0.7)\n",
        "    print(\"最终有效股票列表：\", valid_tickers)"
      ],
      "metadata": {
        "id": "RQ9TqKn9wdax"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pXp471tLwlSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    print(\"开始检查训练、验证和测试数据中是否具有相同的节点（股票），并保存有效股票列表及数据...\")\n",
        "    debug_save_valid_data()\n",
        "    print(\"检查与保存完成。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyqnyFsiwoTk",
        "outputId": "f6a044fc-0658-4d58-8d1d-06c26de889ad"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "开始检查训练、验证和测试数据中是否具有相同的节点（股票），并保存有效股票列表及数据...\n",
            "候选股票总数：503\n",
            "股票 ABNB 数据不完整，已剔除。\n",
            "股票 CARR 数据不完整，已剔除。\n",
            "股票 CEG 数据不完整，已剔除。\n",
            "股票 GEHC 数据不完整，已剔除。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$GEV: possibly delisted; no price data found  (1d 2019-01-01 -> 2022-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1546318800, endDate = 1672462800\")\n",
            "ERROR:yfinance:$GEV: possibly delisted; no price data found  (1d 2023-01-01 -> 2023-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1672549200, endDate = 1703998800\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "股票 GEV 数据不完整，已剔除。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$KVUE: possibly delisted; no price data found  (1d 2019-01-01 -> 2022-12-31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "股票 KVUE 数据不完整，已剔除。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:Could not get exchangeTimezoneName for ticker 'LEN' reason: 'chart'\n",
            "ERROR:yfinance:$LEN: possibly delisted; no timezone found\n",
            "ERROR:yfinance:Could not get exchangeTimezoneName for ticker 'LEN' reason: 'chart'\n",
            "ERROR:yfinance:$LEN: possibly delisted; no timezone found\n",
            "ERROR:yfinance:Could not get exchangeTimezoneName for ticker 'LEN' reason: 'chart'\n",
            "ERROR:yfinance:$LEN: possibly delisted; no timezone found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "股票 LEN 数据不完整，已剔除。\n",
            "股票 OTIS 数据不完整，已剔除。\n",
            "股票 PLTR 数据不完整，已剔除。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$SW: possibly delisted; no price data found  (1d 2019-01-01 -> 2022-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1546318800, endDate = 1672462800\")\n",
            "ERROR:yfinance:$SW: possibly delisted; no price data found  (1d 2023-01-01 -> 2023-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1672549200, endDate = 1703998800\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "股票 SW 数据不完整，已剔除。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$SOLV: possibly delisted; no price data found  (1d 2019-01-01 -> 2022-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1546318800, endDate = 1672462800\")\n",
            "ERROR:yfinance:$SOLV: possibly delisted; no price data found  (1d 2023-01-01 -> 2023-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1672549200, endDate = 1703998800\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "股票 SOLV 数据不完整，已剔除。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$VLTO: possibly delisted; no price data found  (1d 2019-01-01 -> 2022-12-31) (Yahoo error = \"Data doesn't exist for startDate = 1546318800, endDate = 1672462800\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "股票 VLTO 数据不完整，已剔除。\n",
            "数据完整的股票数量：491\n",
            "有效股票列表已保存到: ./data/sp500/valid_tickers.csv\n",
            "保存 MMM 的全数据...\n",
            "保存 AOS 的全数据...\n",
            "保存 ABT 的全数据...\n",
            "保存 ABBV 的全数据...\n",
            "保存 ACN 的全数据...\n",
            "保存 ADBE 的全数据...\n",
            "保存 AMD 的全数据...\n",
            "保存 AES 的全数据...\n",
            "保存 AFL 的全数据...\n",
            "保存 A 的全数据...\n",
            "保存 APD 的全数据...\n",
            "保存 AKAM 的全数据...\n",
            "保存 ALB 的全数据...\n",
            "保存 ARE 的全数据...\n",
            "保存 ALGN 的全数据...\n",
            "保存 ALLE 的全数据...\n",
            "保存 LNT 的全数据...\n",
            "保存 ALL 的全数据...\n",
            "保存 GOOGL 的全数据...\n",
            "保存 GOOG 的全数据...\n",
            "保存 MO 的全数据...\n",
            "保存 AMZN 的全数据...\n",
            "保存 AMCR 的全数据...\n",
            "保存 AEE 的全数据...\n",
            "保存 AEP 的全数据...\n",
            "保存 AXP 的全数据...\n",
            "保存 AIG 的全数据...\n",
            "保存 AMT 的全数据...\n",
            "保存 AWK 的全数据...\n",
            "保存 AMP 的全数据...\n",
            "保存 AME 的全数据...\n",
            "保存 AMGN 的全数据...\n",
            "保存 APH 的全数据...\n",
            "保存 ADI 的全数据...\n",
            "保存 ANSS 的全数据...\n",
            "保存 AON 的全数据...\n",
            "保存 APA 的全数据...\n",
            "保存 APO 的全数据...\n",
            "保存 AAPL 的全数据...\n",
            "保存 AMAT 的全数据...\n",
            "保存 APTV 的全数据...\n",
            "保存 ACGL 的全数据...\n",
            "保存 ADM 的全数据...\n",
            "保存 ANET 的全数据...\n",
            "保存 AJG 的全数据...\n",
            "保存 AIZ 的全数据...\n",
            "保存 T 的全数据...\n",
            "保存 ATO 的全数据...\n",
            "保存 ADSK 的全数据...\n",
            "保存 ADP 的全数据...\n",
            "保存 AZO 的全数据...\n",
            "保存 AVB 的全数据...\n",
            "保存 AVY 的全数据...\n",
            "保存 AXON 的全数据...\n",
            "保存 BKR 的全数据...\n",
            "保存 BALL 的全数据...\n",
            "保存 BAC 的全数据...\n",
            "保存 BAX 的全数据...\n",
            "保存 BDX 的全数据...\n",
            "保存 BRK-B 的全数据...\n",
            "保存 BBY 的全数据...\n",
            "保存 TECH 的全数据...\n",
            "保存 BIIB 的全数据...\n",
            "保存 BLK 的全数据...\n",
            "保存 BX 的全数据...\n",
            "保存 BK 的全数据...\n",
            "保存 BA 的全数据...\n",
            "保存 BKNG 的全数据...\n",
            "保存 BWA 的全数据...\n",
            "保存 BSX 的全数据...\n",
            "保存 BMY 的全数据...\n",
            "保存 AVGO 的全数据...\n",
            "保存 BR 的全数据...\n",
            "保存 BRO 的全数据...\n",
            "保存 BF-B 的全数据...\n",
            "保存 BLDR 的全数据...\n",
            "保存 BG 的全数据...\n",
            "保存 BXP 的全数据...\n",
            "保存 CHRW 的全数据...\n",
            "保存 CDNS 的全数据...\n",
            "保存 CZR 的全数据...\n",
            "保存 CPT 的全数据...\n",
            "保存 CPB 的全数据...\n",
            "保存 COF 的全数据...\n",
            "保存 CAH 的全数据...\n",
            "保存 KMX 的全数据...\n",
            "保存 CCL 的全数据...\n",
            "保存 CAT 的全数据...\n",
            "保存 CBOE 的全数据...\n",
            "保存 CBRE 的全数据...\n",
            "保存 CDW 的全数据...\n",
            "保存 CE 的全数据...\n",
            "保存 COR 的全数据...\n",
            "保存 CNC 的全数据...\n",
            "保存 CNP 的全数据...\n",
            "保存 CF 的全数据...\n",
            "保存 CRL 的全数据...\n",
            "保存 SCHW 的全数据...\n",
            "保存 CHTR 的全数据...\n",
            "保存 CVX 的全数据...\n",
            "保存 CMG 的全数据...\n",
            "保存 CB 的全数据...\n",
            "保存 CHD 的全数据...\n",
            "保存 CI 的全数据...\n",
            "保存 CINF 的全数据...\n",
            "保存 CTAS 的全数据...\n",
            "保存 CSCO 的全数据...\n",
            "保存 C 的全数据...\n",
            "保存 CFG 的全数据...\n",
            "保存 CLX 的全数据...\n",
            "保存 CME 的全数据...\n",
            "保存 CMS 的全数据...\n",
            "保存 KO 的全数据...\n",
            "保存 CTSH 的全数据...\n",
            "保存 CL 的全数据...\n",
            "保存 CMCSA 的全数据...\n",
            "保存 CAG 的全数据...\n",
            "保存 COP 的全数据...\n",
            "保存 ED 的全数据...\n",
            "保存 STZ 的全数据...\n",
            "保存 COO 的全数据...\n",
            "保存 CPRT 的全数据...\n",
            "保存 GLW 的全数据...\n",
            "保存 CPAY 的全数据...\n",
            "保存 CTVA 的全数据...\n",
            "保存 CSGP 的全数据...\n",
            "保存 COST 的全数据...\n",
            "保存 CTRA 的全数据...\n",
            "保存 CRWD 的全数据...\n",
            "保存 CCI 的全数据...\n",
            "保存 CSX 的全数据...\n",
            "保存 CMI 的全数据...\n",
            "保存 CVS 的全数据...\n",
            "保存 DHR 的全数据...\n",
            "保存 DRI 的全数据...\n",
            "保存 DVA 的全数据...\n",
            "保存 DAY 的全数据...\n",
            "保存 DECK 的全数据...\n",
            "保存 DE 的全数据...\n",
            "保存 DELL 的全数据...\n",
            "保存 DAL 的全数据...\n",
            "保存 DVN 的全数据...\n",
            "保存 DXCM 的全数据...\n",
            "保存 FANG 的全数据...\n",
            "保存 DLR 的全数据...\n",
            "保存 DFS 的全数据...\n",
            "保存 DG 的全数据...\n",
            "保存 DLTR 的全数据...\n",
            "保存 D 的全数据...\n",
            "保存 DPZ 的全数据...\n",
            "保存 DOV 的全数据...\n",
            "保存 DOW 的全数据...\n",
            "保存 DHI 的全数据...\n",
            "保存 DTE 的全数据...\n",
            "保存 DUK 的全数据...\n",
            "保存 DD 的全数据...\n",
            "保存 EMN 的全数据...\n",
            "保存 ETN 的全数据...\n",
            "保存 EBAY 的全数据...\n",
            "保存 ECL 的全数据...\n",
            "保存 EIX 的全数据...\n",
            "保存 EW 的全数据...\n",
            "保存 EA 的全数据...\n",
            "保存 ELV 的全数据...\n",
            "保存 EMR 的全数据...\n",
            "保存 ENPH 的全数据...\n",
            "保存 ETR 的全数据...\n",
            "保存 EOG 的全数据...\n",
            "保存 EPAM 的全数据...\n",
            "保存 EQT 的全数据...\n",
            "保存 EFX 的全数据...\n",
            "保存 EQIX 的全数据...\n",
            "保存 EQR 的全数据...\n",
            "保存 ERIE 的全数据...\n",
            "保存 ESS 的全数据...\n",
            "保存 EL 的全数据...\n",
            "保存 EG 的全数据...\n",
            "保存 EVRG 的全数据...\n",
            "保存 ES 的全数据...\n",
            "保存 EXC 的全数据...\n",
            "保存 EXPE 的全数据...\n",
            "保存 EXPD 的全数据...\n",
            "保存 EXR 的全数据...\n",
            "保存 XOM 的全数据...\n",
            "保存 FFIV 的全数据...\n",
            "保存 FDS 的全数据...\n",
            "保存 FICO 的全数据...\n",
            "保存 FAST 的全数据...\n",
            "保存 FRT 的全数据...\n",
            "保存 FDX 的全数据...\n",
            "保存 FIS 的全数据...\n",
            "保存 FITB 的全数据...\n",
            "保存 FSLR 的全数据...\n",
            "保存 FE 的全数据...\n",
            "保存 FI 的全数据...\n",
            "保存 FMC 的全数据...\n",
            "保存 F 的全数据...\n",
            "保存 FTNT 的全数据...\n",
            "保存 FTV 的全数据...\n",
            "保存 FOXA 的全数据...\n",
            "保存 FOX 的全数据...\n",
            "保存 BEN 的全数据...\n",
            "保存 FCX 的全数据...\n",
            "保存 GRMN 的全数据...\n",
            "保存 IT 的全数据...\n",
            "保存 GE 的全数据...\n",
            "保存 GEN 的全数据...\n",
            "保存 GNRC 的全数据...\n",
            "保存 GD 的全数据...\n",
            "保存 GIS 的全数据...\n",
            "保存 GM 的全数据...\n",
            "保存 GPC 的全数据...\n",
            "保存 GILD 的全数据...\n",
            "保存 GPN 的全数据...\n",
            "保存 GL 的全数据...\n",
            "保存 GDDY 的全数据...\n",
            "保存 GS 的全数据...\n",
            "保存 HAL 的全数据...\n",
            "保存 HIG 的全数据...\n",
            "保存 HAS 的全数据...\n",
            "保存 HCA 的全数据...\n",
            "保存 DOC 的全数据...\n",
            "保存 HSIC 的全数据...\n",
            "保存 HSY 的全数据...\n",
            "保存 HES 的全数据...\n",
            "保存 HPE 的全数据...\n",
            "保存 HLT 的全数据...\n",
            "保存 HOLX 的全数据...\n",
            "保存 HD 的全数据...\n",
            "保存 HON 的全数据...\n",
            "保存 HRL 的全数据...\n",
            "保存 HST 的全数据...\n",
            "保存 HWM 的全数据...\n",
            "保存 HPQ 的全数据...\n",
            "保存 HUBB 的全数据...\n",
            "保存 HUM 的全数据...\n",
            "保存 HBAN 的全数据...\n",
            "保存 HII 的全数据...\n",
            "保存 IBM 的全数据...\n",
            "保存 IEX 的全数据...\n",
            "保存 IDXX 的全数据...\n",
            "保存 ITW 的全数据...\n",
            "保存 INCY 的全数据...\n",
            "保存 IR 的全数据...\n",
            "保存 PODD 的全数据...\n",
            "保存 INTC 的全数据...\n",
            "保存 ICE 的全数据...\n",
            "保存 IFF 的全数据...\n",
            "保存 IP 的全数据...\n",
            "保存 IPG 的全数据...\n",
            "保存 INTU 的全数据...\n",
            "保存 ISRG 的全数据...\n",
            "保存 IVZ 的全数据...\n",
            "保存 INVH 的全数据...\n",
            "保存 IQV 的全数据...\n",
            "保存 IRM 的全数据...\n",
            "保存 JBHT 的全数据...\n",
            "保存 JBL 的全数据...\n",
            "保存 JKHY 的全数据...\n",
            "保存 J 的全数据...\n",
            "保存 JNJ 的全数据...\n",
            "保存 JCI 的全数据...\n",
            "保存 JPM 的全数据...\n",
            "保存 JNPR 的全数据...\n",
            "保存 K 的全数据...\n",
            "保存 KDP 的全数据...\n",
            "保存 KEY 的全数据...\n",
            "保存 KEYS 的全数据...\n",
            "保存 KMB 的全数据...\n",
            "保存 KIM 的全数据...\n",
            "保存 KMI 的全数据...\n",
            "保存 KKR 的全数据...\n",
            "保存 KLAC 的全数据...\n",
            "保存 KHC 的全数据...\n",
            "保存 KR 的全数据...\n",
            "保存 LHX 的全数据...\n",
            "保存 LH 的全数据...\n",
            "保存 LRCX 的全数据...\n",
            "保存 LW 的全数据...\n",
            "保存 LVS 的全数据...\n",
            "保存 LDOS 的全数据...\n",
            "保存 LII 的全数据...\n",
            "保存 LLY 的全数据...\n",
            "保存 LIN 的全数据...\n",
            "保存 LYV 的全数据...\n",
            "保存 LKQ 的全数据...\n",
            "保存 LMT 的全数据...\n",
            "保存 L 的全数据...\n",
            "保存 LOW 的全数据...\n",
            "保存 LULU 的全数据...\n",
            "保存 LYB 的全数据...\n",
            "保存 MTB 的全数据...\n",
            "保存 MPC 的全数据...\n",
            "保存 MKTX 的全数据...\n",
            "保存 MAR 的全数据...\n",
            "保存 MMC 的全数据...\n",
            "保存 MLM 的全数据...\n",
            "保存 MAS 的全数据...\n",
            "保存 MA 的全数据...\n",
            "保存 MTCH 的全数据...\n",
            "保存 MKC 的全数据...\n",
            "保存 MCD 的全数据...\n",
            "保存 MCK 的全数据...\n",
            "保存 MDT 的全数据...\n",
            "保存 MRK 的全数据...\n",
            "保存 META 的全数据...\n",
            "保存 MET 的全数据...\n",
            "保存 MTD 的全数据...\n",
            "保存 MGM 的全数据...\n",
            "保存 MCHP 的全数据...\n",
            "保存 MU 的全数据...\n",
            "保存 MSFT 的全数据...\n",
            "保存 MAA 的全数据...\n",
            "保存 MRNA 的全数据...\n",
            "保存 MHK 的全数据...\n",
            "保存 MOH 的全数据...\n",
            "保存 TAP 的全数据...\n",
            "保存 MDLZ 的全数据...\n",
            "保存 MPWR 的全数据...\n",
            "保存 MNST 的全数据...\n",
            "保存 MCO 的全数据...\n",
            "保存 MS 的全数据...\n",
            "保存 MOS 的全数据...\n",
            "保存 MSI 的全数据...\n",
            "保存 MSCI 的全数据...\n",
            "保存 NDAQ 的全数据...\n",
            "保存 NTAP 的全数据...\n",
            "保存 NFLX 的全数据...\n",
            "保存 NEM 的全数据...\n",
            "保存 NWSA 的全数据...\n",
            "保存 NWS 的全数据...\n",
            "保存 NEE 的全数据...\n",
            "保存 NKE 的全数据...\n",
            "保存 NI 的全数据...\n",
            "保存 NDSN 的全数据...\n",
            "保存 NSC 的全数据...\n",
            "保存 NTRS 的全数据...\n",
            "保存 NOC 的全数据...\n",
            "保存 NCLH 的全数据...\n",
            "保存 NRG 的全数据...\n",
            "保存 NUE 的全数据...\n",
            "保存 NVDA 的全数据...\n",
            "保存 NVR 的全数据...\n",
            "保存 NXPI 的全数据...\n",
            "保存 ORLY 的全数据...\n",
            "保存 OXY 的全数据...\n",
            "保存 ODFL 的全数据...\n",
            "保存 OMC 的全数据...\n",
            "保存 ON 的全数据...\n",
            "保存 OKE 的全数据...\n",
            "保存 ORCL 的全数据...\n",
            "保存 PCAR 的全数据...\n",
            "保存 PKG 的全数据...\n",
            "保存 PANW 的全数据...\n",
            "保存 PARA 的全数据...\n",
            "保存 PH 的全数据...\n",
            "保存 PAYX 的全数据...\n",
            "保存 PAYC 的全数据...\n",
            "保存 PYPL 的全数据...\n",
            "保存 PNR 的全数据...\n",
            "保存 PEP 的全数据...\n",
            "保存 PFE 的全数据...\n",
            "保存 PCG 的全数据...\n",
            "保存 PM 的全数据...\n",
            "保存 PSX 的全数据...\n",
            "保存 PNW 的全数据...\n",
            "保存 PNC 的全数据...\n",
            "保存 POOL 的全数据...\n",
            "保存 PPG 的全数据...\n",
            "保存 PPL 的全数据...\n",
            "保存 PFG 的全数据...\n",
            "保存 PG 的全数据...\n",
            "保存 PGR 的全数据...\n",
            "保存 PLD 的全数据...\n",
            "保存 PRU 的全数据...\n",
            "保存 PEG 的全数据...\n",
            "保存 PTC 的全数据...\n",
            "保存 PSA 的全数据...\n",
            "保存 PHM 的全数据...\n",
            "保存 PWR 的全数据...\n",
            "保存 QCOM 的全数据...\n",
            "保存 DGX 的全数据...\n",
            "保存 RL 的全数据...\n",
            "保存 RJF 的全数据...\n",
            "保存 RTX 的全数据...\n",
            "保存 O 的全数据...\n",
            "保存 REG 的全数据...\n",
            "保存 REGN 的全数据...\n",
            "保存 RF 的全数据...\n",
            "保存 RSG 的全数据...\n",
            "保存 RMD 的全数据...\n",
            "保存 RVTY 的全数据...\n",
            "保存 ROK 的全数据...\n",
            "保存 ROL 的全数据...\n",
            "保存 ROP 的全数据...\n",
            "保存 ROST 的全数据...\n",
            "保存 RCL 的全数据...\n",
            "保存 SPGI 的全数据...\n",
            "保存 CRM 的全数据...\n",
            "保存 SBAC 的全数据...\n",
            "保存 SLB 的全数据...\n",
            "保存 STX 的全数据...\n",
            "保存 SRE 的全数据...\n",
            "保存 NOW 的全数据...\n",
            "保存 SHW 的全数据...\n",
            "保存 SPG 的全数据...\n",
            "保存 SWKS 的全数据...\n",
            "保存 SJM 的全数据...\n",
            "保存 SNA 的全数据...\n",
            "保存 SO 的全数据...\n",
            "保存 LUV 的全数据...\n",
            "保存 SWK 的全数据...\n",
            "保存 SBUX 的全数据...\n",
            "保存 STT 的全数据...\n",
            "保存 STLD 的全数据...\n",
            "保存 STE 的全数据...\n",
            "保存 SYK 的全数据...\n",
            "保存 SMCI 的全数据...\n",
            "保存 SYF 的全数据...\n",
            "保存 SNPS 的全数据...\n",
            "保存 SYY 的全数据...\n",
            "保存 TMUS 的全数据...\n",
            "保存 TROW 的全数据...\n",
            "保存 TTWO 的全数据...\n",
            "保存 TPR 的全数据...\n",
            "保存 TRGP 的全数据...\n",
            "保存 TGT 的全数据...\n",
            "保存 TEL 的全数据...\n",
            "保存 TDY 的全数据...\n",
            "保存 TFX 的全数据...\n",
            "保存 TER 的全数据...\n",
            "保存 TSLA 的全数据...\n",
            "保存 TXN 的全数据...\n",
            "保存 TPL 的全数据...\n",
            "保存 TXT 的全数据...\n",
            "保存 TMO 的全数据...\n",
            "保存 TJX 的全数据...\n",
            "保存 TSCO 的全数据...\n",
            "保存 TT 的全数据...\n",
            "保存 TDG 的全数据...\n",
            "保存 TRV 的全数据...\n",
            "保存 TRMB 的全数据...\n",
            "保存 TFC 的全数据...\n",
            "保存 TYL 的全数据...\n",
            "保存 TSN 的全数据...\n",
            "保存 USB 的全数据...\n",
            "保存 UBER 的全数据...\n",
            "保存 UDR 的全数据...\n",
            "保存 ULTA 的全数据...\n",
            "保存 UNP 的全数据...\n",
            "保存 UAL 的全数据...\n",
            "保存 UPS 的全数据...\n",
            "保存 URI 的全数据...\n",
            "保存 UNH 的全数据...\n",
            "保存 UHS 的全数据...\n",
            "保存 VLO 的全数据...\n",
            "保存 VTR 的全数据...\n",
            "保存 VRSN 的全数据...\n",
            "保存 VRSK 的全数据...\n",
            "保存 VZ 的全数据...\n",
            "保存 VRTX 的全数据...\n",
            "保存 VTRS 的全数据...\n",
            "保存 VICI 的全数据...\n",
            "保存 V 的全数据...\n",
            "保存 VST 的全数据...\n",
            "保存 VMC 的全数据...\n",
            "保存 WRB 的全数据...\n",
            "保存 GWW 的全数据...\n",
            "保存 WAB 的全数据...\n",
            "保存 WBA 的全数据...\n",
            "保存 WMT 的全数据...\n",
            "保存 DIS 的全数据...\n",
            "保存 WBD 的全数据...\n",
            "保存 WM 的全数据...\n",
            "保存 WAT 的全数据...\n",
            "保存 WEC 的全数据...\n",
            "保存 WFC 的全数据...\n",
            "保存 WELL 的全数据...\n",
            "保存 WST 的全数据...\n",
            "保存 WDC 的全数据...\n",
            "保存 WY 的全数据...\n",
            "保存 WMB 的全数据...\n",
            "保存 WTW 的全数据...\n",
            "保存 WDAY 的全数据...\n",
            "保存 WYNN 的全数据...\n",
            "保存 XEL 的全数据...\n",
            "保存 XYL 的全数据...\n",
            "保存 YUM 的全数据...\n",
            "保存 ZBRA 的全数据...\n",
            "保存 ZBH 的全数据...\n",
            "保存 ZTS 的全数据...\n",
            "所有有效股票数据保存完成。\n",
            "最终有效股票列表： ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'AON', 'APA', 'APO', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BAX', 'BDX', 'BRK-B', 'BBY', 'TECH', 'BIIB', 'BLK', 'BX', 'BK', 'BA', 'BKNG', 'BWA', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF-B', 'BLDR', 'BG', 'BXP', 'CHRW', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'COR', 'CNC', 'CNP', 'CF', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CAG', 'COP', 'ED', 'STZ', 'COO', 'CPRT', 'GLW', 'CPAY', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CRWD', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DVA', 'DAY', 'DECK', 'DE', 'DELL', 'DAL', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ERIE', 'ESS', 'EL', 'EG', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'FMC', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GE', 'GEN', 'GNRC', 'GD', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GDDY', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'DOC', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'JNPR', 'K', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KKR', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LII', 'LLY', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SMCI', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TPL', 'TXT', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VTRS', 'VICI', 'V', 'VST', 'VMC', 'WRB', 'GWW', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WY', 'WMB', 'WTW', 'WDAY', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZTS']\n",
            "检查与保存完成。\n"
          ]
        }
      ]
    }
  ]
}